{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering-Based Regime Identification Methods\n",
    "\n",
    "This notebook implements four clustering approaches for macroeconomic regime detection:\n",
    "\n",
    "1. Fuzzy C-Means Clustering\n",
    "2. Modified K-Means (Oliveira et al., 2025)\n",
    "3. Vanilla K-Means with Probabilistic Assignment\n",
    "4. Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_series(x, tcode):\n",
    "    if tcode == 1: return x\n",
    "    elif tcode == 2: return x.diff()\n",
    "    elif tcode == 3: return x.diff().diff()\n",
    "    elif tcode == 4: return np.log(x)\n",
    "    elif tcode == 5: return np.log(x).diff()\n",
    "    elif tcode == 6: return np.log(x).diff().diff()\n",
    "    elif tcode == 7: return x.pct_change()\n",
    "    else: raise ValueError(f\"Unknown tcode: {tcode}\")\n",
    "\n",
    "def load_data(filepath='../data/macro_dataset.csv', start_date='1962-07-01'):\n",
    "    data = pd.read_csv(filepath, skiprows=[1], index_col=0)\n",
    "    data.columns = [c.upper() for c in data.columns]\n",
    "    data = data.loc[pd.notna(data.index), :]\n",
    "    data.index = pd.date_range(start=\"1959-01-01\", freq=\"MS\", periods=len(data))\n",
    "    \n",
    "    tcodes = pd.read_csv(filepath, nrows=1, index_col=0)\n",
    "    tcodes.columns = [c.upper() for c in tcodes.columns]\n",
    "    \n",
    "    data = data.apply(lambda x: transform_series(x, tcodes[x.name].item()))\n",
    "    data = data.dropna(axis=1, subset=[pd.Timestamp(start_date)])\n",
    "    data = data.fillna(method='ffill').dropna()\n",
    "    data = data[data.index >= start_date]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data_std = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "    return data_std\n",
    "\n",
    "df = load_data()\n",
    "X = df.values\n",
    "dates = df.index\n",
    "T, p = X.shape\n",
    "\n",
    "print(f\"Data loaded: {T} observations x {p} features\")\n",
    "print(f\"Date range: {dates[0].strftime('%Y-%m')} to {dates[-1].strftime('%Y-%m')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "print(f\"Target number of regimes: K = {K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fuzzy C-Means Clustering\n",
    "\n",
    "Fuzzy C-Means allows each observation to belong to multiple clusters with varying degrees of membership.\n",
    "\n",
    "**Objective function:**\n",
    "$$\\min_{\\{c_i\\}, \\{w_{i,t}\\}} \\sum_{t=1}^{T} \\sum_{i=1}^{K} w_{i,t}^m \\|x_t - c_i\\|^2$$\n",
    "\n",
    "subject to $\\sum_{i=1}^{K} w_{i,t} = 1$ and $w_{i,t} \\geq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyCMeans:\n",
    "    \"\"\"\n",
    "    Fuzzy C-Means clustering implementation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_clusters : int\n",
    "        Number of clusters\n",
    "    m : float\n",
    "        Fuzziness parameter (m > 1). Higher values = softer assignments.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=4, m=2.0, max_iter=300, tol=1e-6, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.m = m\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.centers_ = None\n",
    "        self.membership_ = None\n",
    "        self.n_iter_ = 0\n",
    "        \n",
    "    def fit(self, X):\n",
    "        np.random.seed(self.random_state)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize membership randomly\n",
    "        U = np.random.rand(n_samples, self.n_clusters)\n",
    "        U = U / U.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            U_old = U.copy()\n",
    "            \n",
    "            # Update centroids\n",
    "            Um = U ** self.m\n",
    "            self.centers_ = (Um.T @ X) / Um.sum(axis=0, keepdims=True).T\n",
    "            \n",
    "            # Update membership\n",
    "            distances = cdist(X, self.centers_, metric='euclidean')\n",
    "            distances = np.maximum(distances, 1e-10)\n",
    "            \n",
    "            power = 2 / (self.m - 1)\n",
    "            U = 1 / (distances ** power)\n",
    "            U = U / U.sum(axis=1, keepdims=True)\n",
    "            \n",
    "            self.n_iter_ = iteration + 1\n",
    "            \n",
    "            # Check convergence\n",
    "            if np.linalg.norm(U - U_old) < self.tol:\n",
    "                print(f\"Converged after {self.n_iter_} iterations\")\n",
    "                break\n",
    "        \n",
    "        self.membership_ = U\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return soft membership weights\"\"\"\n",
    "        distances = cdist(X, self.centers_, metric='euclidean')\n",
    "        distances = np.maximum(distances, 1e-10)\n",
    "        power = 2 / (self.m - 1)\n",
    "        U = 1 / (distances ** power)\n",
    "        return U / U.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return hard labels\"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Fuzzy C-Means\n",
    "print(\"Fitting Fuzzy C-Means...\")\n",
    "fcm = FuzzyCMeans(n_clusters=K, m=2.0, random_state=42)\n",
    "fcm.fit(X)\n",
    "\n",
    "fcm_soft = fcm.predict_proba(X)\n",
    "fcm_hard = fcm.predict(X)\n",
    "\n",
    "print(f\"\\nMembership matrix shape: {fcm_soft.shape}\")\n",
    "print(f\"\\nRegime distribution:\")\n",
    "unique, counts = np.unique(fcm_hard, return_counts=True)\n",
    "for r, c in zip(unique, counts):\n",
    "    print(f\"  Regime {r}: {c} months ({100*c/T:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check membership values\n",
    "print(\"Sample soft assignments (first 10 periods):\")\n",
    "print(pd.DataFrame(fcm_soft[:10], columns=[f'R{i}' for i in range(K)]).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modified K-Means (Oliveira et al., 2025)\n",
    "\n",
    "Two-step approach:\n",
    "1. Identify \"atypical\" periods (outliers) based on distance from cluster centers\n",
    "2. Fit k-means on typical periods only, then assign all periods probabilistically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedKMeans:\n",
    "    \"\"\"\n",
    "    Modified K-Means with atypical period detection.\n",
    "    Based on Oliveira et al. (2025).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=4, atypical_threshold=2.0, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.atypical_threshold = atypical_threshold\n",
    "        self.random_state = random_state\n",
    "        self.kmeans_ = None\n",
    "        self.centers_ = None\n",
    "        self.atypical_mask_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        print(\"  Step 1: Initial k-means for outlier detection...\")\n",
    "        initial_km = KMeans(n_clusters=self.n_clusters, random_state=self.random_state, n_init=10)\n",
    "        initial_labels = initial_km.fit_predict(X)\n",
    "        \n",
    "        # Compute distances to assigned centers\n",
    "        distances = np.array([\n",
    "            np.linalg.norm(X[i] - initial_km.cluster_centers_[initial_labels[i]])\n",
    "            for i in range(n_samples)\n",
    "        ])\n",
    "        \n",
    "        # Flag atypical periods\n",
    "        mean_d, std_d = distances.mean(), distances.std()\n",
    "        self.atypical_mask_ = distances > (mean_d + self.atypical_threshold * std_d)\n",
    "        n_atypical = self.atypical_mask_.sum()\n",
    "        print(f\"  Found {n_atypical} atypical periods ({100*n_atypical/n_samples:.1f}%)\")\n",
    "        \n",
    "        # Re-fit on typical periods only\n",
    "        print(\"  Step 2: Re-fitting on typical periods...\")\n",
    "        X_typical = X[~self.atypical_mask_]\n",
    "        self.kmeans_ = KMeans(n_clusters=self.n_clusters, random_state=self.random_state, n_init=10)\n",
    "        self.kmeans_.fit(X_typical)\n",
    "        self.centers_ = self.kmeans_.cluster_centers_\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Inverse-distance based probability assignment\"\"\"\n",
    "        distances = cdist(X, self.centers_, metric='euclidean')\n",
    "        distances = np.maximum(distances, 1e-10)\n",
    "        inv_dist = 1 / distances\n",
    "        return inv_dist / inv_dist.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "    \n",
    "    def get_atypical_periods(self, dates):\n",
    "        \"\"\"Return dates of atypical periods\"\"\"\n",
    "        return dates[self.atypical_mask_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Modified K-Means\n",
    "print(\"Fitting Modified K-Means...\")\n",
    "mkm = ModifiedKMeans(n_clusters=K, atypical_threshold=2.0, random_state=42)\n",
    "mkm.fit(X)\n",
    "\n",
    "mkm_soft = mkm.predict_proba(X)\n",
    "mkm_hard = mkm.predict(X)\n",
    "\n",
    "# Show atypical periods\n",
    "atypical_dates = mkm.get_atypical_periods(dates)\n",
    "print(f\"\\nAtypical periods detected:\")\n",
    "for d in atypical_dates[:10]:\n",
    "    print(f\"  {d.strftime('%Y-%m')}\")\n",
    "if len(atypical_dates) > 10:\n",
    "    print(f\"  ... and {len(atypical_dates)-10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regime distribution\n",
    "print(\"\\nRegime distribution (Modified K-Means):\")\n",
    "unique, counts = np.unique(mkm_hard, return_counts=True)\n",
    "for r, c in zip(unique, counts):\n",
    "    print(f\"  Regime {r}: {c} months ({100*c/T:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vanilla K-Means with Probabilistic Assignment\n",
    "\n",
    "Standard k-means, but we derive soft assignments from inverse distances:\n",
    "$$w_{i,t} = \\frac{1/d_{i,t}}{\\sum_j 1/d_{j,t}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaKMeansProb:\n",
    "    \"\"\"Standard K-Means with probabilistic (soft) assignment\"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=4, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.kmeans_ = None\n",
    "        self.centers_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.kmeans_ = KMeans(n_clusters=self.n_clusters, random_state=self.random_state, n_init=10)\n",
    "        self.kmeans_.fit(X)\n",
    "        self.centers_ = self.kmeans_.cluster_centers_\n",
    "        print(f\"K-Means converged. Inertia: {self.kmeans_.inertia_:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        distances = cdist(X, self.centers_, metric='euclidean')\n",
    "        distances = np.maximum(distances, 1e-10)\n",
    "        inv_dist = 1 / distances\n",
    "        return inv_dist / inv_dist.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.kmeans_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Vanilla K-Means\n",
    "print(\"Fitting Vanilla K-Means...\")\n",
    "vkm = VanillaKMeansProb(n_clusters=K, random_state=42)\n",
    "vkm.fit(X)\n",
    "\n",
    "vkm_soft = vkm.predict_proba(X)\n",
    "vkm_hard = vkm.predict(X)\n",
    "\n",
    "print(\"\\nRegime distribution (Vanilla K-Means):\")\n",
    "unique, counts = np.unique(vkm_hard, return_counts=True)\n",
    "for r, c in zip(unique, counts):\n",
    "    print(f\"  Regime {r}: {c} months ({100*c/T:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gaussian Mixture Model (GMM)\n",
    "\n",
    "Model-based clustering assuming data comes from a mixture of Gaussians:\n",
    "$$p(x_t) = \\sum_{i=1}^{K} \\pi_i \\phi(x_t; \\mu_i, \\Sigma_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GMM\n",
    "# Use diagonal covariance for numerical stability with high-dimensional data\n",
    "print(\"Fitting Gaussian Mixture Model...\")\n",
    "gmm = GaussianMixture(\n",
    "    n_components=K,\n",
    "    covariance_type='diag',  # diagonal covariance for stability\n",
    "    random_state=42,\n",
    "    n_init=10,\n",
    "    max_iter=200,\n",
    "    verbose=0\n",
    ")\n",
    "gmm.fit(X)\n",
    "\n",
    "gmm_soft = gmm.predict_proba(X)\n",
    "gmm_hard = gmm.predict(X)\n",
    "\n",
    "print(f\"GMM converged: {gmm.converged_}\")\n",
    "print(f\"Log-likelihood: {gmm.lower_bound_:.2f}\")\n",
    "print(f\"Mixing proportions: {gmm.weights_.round(3)}\")\n",
    "\n",
    "print(\"\\nRegime distribution (GMM):\")\n",
    "unique, counts = np.unique(gmm_hard, return_counts=True)\n",
    "for r, c in zip(unique, counts):\n",
    "    print(f\"  Regime {r}: {c} months ({100*c/T:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all results\n",
    "methods = ['Fuzzy C-Means', 'Modified K-Means', 'Vanilla K-Means', 'GMM']\n",
    "\n",
    "soft_assignments = {\n",
    "    'Fuzzy C-Means': fcm_soft,\n",
    "    'Modified K-Means': mkm_soft,\n",
    "    'Vanilla K-Means': vkm_soft,\n",
    "    'GMM': gmm_soft,\n",
    "}\n",
    "\n",
    "hard_assignments = {\n",
    "    'Fuzzy C-Means': fcm_hard,\n",
    "    'Modified K-Means': mkm_hard,\n",
    "    'Vanilla K-Means': vkm_hard,\n",
    "    'GMM': gmm_hard,\n",
    "}\n",
    "\n",
    "print(\"All clustering methods fitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regime assignments over time\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, K))\n",
    "\n",
    "fig, axes = plt.subplots(len(methods), 1, figsize=(14, 3*len(methods)), sharex=True)\n",
    "\n",
    "for idx, method in enumerate(methods):\n",
    "    ax = axes[idx]\n",
    "    hard = hard_assignments[method]\n",
    "    \n",
    "    for t in range(len(dates)):\n",
    "        ax.axvspan(dates[t], dates[min(t+1, len(dates)-1)], \n",
    "                   color=colors[hard[t]], alpha=0.7)\n",
    "    \n",
    "    ax.set_ylabel(method, fontsize=10)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add regime distribution annotation\n",
    "    regime_counts = pd.Series(hard).value_counts().sort_index()\n",
    "    dist_text = ', '.join([f'R{i}:{100*c/len(hard):.0f}%' for i, c in regime_counts.items()])\n",
    "    ax.text(0.02, 0.85, dist_text, transform=ax.transAxes, fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "\n",
    "# Legend\n",
    "legend_elements = [plt.Rectangle((0,0),1,1, color=colors[i], label=f'Regime {i}') \n",
    "                   for i in range(K)]\n",
    "fig.legend(handles=legend_elements, loc='upper right', ncol=K, bbox_to_anchor=(0.98, 0.98))\n",
    "\n",
    "plt.suptitle('Regime Assignments by Clustering Method', fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-method agreement (Adjusted Rand Index)\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ari_matrix = np.zeros((len(methods), len(methods)))\n",
    "for i, m1 in enumerate(methods):\n",
    "    for j, m2 in enumerate(methods):\n",
    "        ari_matrix[i, j] = adjusted_rand_score(hard_assignments[m1], hard_assignments[m2])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(ari_matrix, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "            xticklabels=methods, yticklabels=methods)\n",
    "plt.title('Cross-Method Agreement (Adjusted Rand Index)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(index=dates)\n",
    "for method in methods:\n",
    "    results_df[f'{method}_hard'] = hard_assignments[method]\n",
    "    for k in range(K):\n",
    "        results_df[f'{method}_soft_R{k}'] = soft_assignments[method][:, k]\n",
    "\n",
    "# results_df.to_csv('../data/clustering_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
